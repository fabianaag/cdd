---
title: "speed-dating"
output:
  html_document:
    df_print: paged
  html_notebook: default
  pdf_document: default
date: "12 de novembro de 2019"
---
### **Universidade Federal de Campina Grande | UFCG**
### **Ciência da Computação **
### **Ciência de Dados Descritiva**
### **Professor**: Nazareno Andrade 
### **Aluno(a)**: Fabiana Alves Gomes

<center>
  ![](../dados/logo.png)
</center>

\newpage

```{r ,warning=FALSE,message=FALSE,echo=FALSE, warning=FALSE}
library(readr, quietly = TRUE, warn.conflicts = FALSE)
library(fmsb, quietly = TRUE, warn.conflicts = FALSE)
library(tidyverse, quietly = TRUE, warn.conflicts = FALSE)
library(ggplot2, warn.conflicts = FALSE, quietly = TRUE)
library(dplyr, warn.conflicts = FALSE, quietly = TRUE)
library(GGally, warn.conflicts = FALSE, quietly = TRUE)
library(broom, warn.conflicts = FALSE, quietly = TRUE)

speed_dating <- read_csv('./speed-dating.csv')

# Seleciona atributos para análise
speed_dating_attributes <- select(speed_dating, like, attr, sinc, intel, fun, amb, shar, prob, age, age_o, gender)
# Limpa linhas que tem NA
speed_dating_attributes <- speed_dating_attributes[complete.cases(speed_dating_attributes),]

dataAll = speed_dating_attributes %>%
            mutate(gender=ifelse(gender=="0", "Mulher", "Homem" ))

dataWomen = speed_dating_attributes %>% 
            filter(gender == "0") %>% 
            select(like, attr, sinc, intel, fun, amb, shar, prob)  

dataMen = speed_dating_attributes %>% 
            filter(gender == "1") %>% 
            select(like, attr, sinc, intel, fun, amb, shar, prob)

```
---

## Introdução 

Este relatório tem como objetivo elucidar uma pergunta utilizando os dados de encontros relâmpagos, também conhecido como speed dating.  

Logo, a pergunta que tentaremos elucidar é:

* O quanto a sinceridade observada no parceiro e os interesses em comum influenciam o like?

Após encontros que duravam 4 minutos os participantes respondiam a um questionário dizendo o que acharam sobre a pessoa com quem tiveram o encontro, no total foram respondidos por volta de 5 mil questionários sobre os encontros.  

Após o tratamento dos dados restaram um total de **4024** respostas do questionário referente aos encontros que podemos analisar. 

Os dados¹ foram coletados em um experimento² pelos professores da ***Columbia Business School***, que disponibilizaram os dados para a comunidade. 

* ¹ Dados - https://github.com/nazareno/ciencia-de-dados-1/tree/master/5-regressao/speed-dating
* ² Experimento - https://faculty.chicagobooth.edu/emir.kamenica/documents/genderDifferences.pdf 

---

## Desenvolvimento 

Utilizaremos de Modelos de Regressão linear para tentar obter informações que possam indicar como a *sinceridade* e os *interesses percebidos em comum* influênciam o quanto um participante do experimento gosta do outro. Para tentar responder essa pergunta podemos comparar modelos que utilizam *sinceridade e interesses compartilhados* com outros modelos e comparar métricas de qualidades desses modelos. 

Em modelos de regressão múltipla é necessário determinar um subconjunto de variáveis independentes que melhor expliquem a variável resposta, isto é, dentre todas as variáveis explicativas disponíveis, devemos encontrar um subconjunto de variáveis importantes para o modelo. 

No total iremos criar os seguintes modelos:

* Um mais abrangente, contendo várias variáveis independentes. 
* Uma variação do modelo abrangente removendo *Interesses compartilhados(shar)* e *Sinceridade(sinc)*.
* Uma variação do modelo abrangente removendo 2 variáveis com maior correlação com a variável dependente.

Para visualizar a distribuição e correlação, utilizamos as cores ciano e magenta sobrepostas, os picos que apresentarem a cor ciano indicam mais votos de homens naquela faixa, e picos com a cor magenta indicam predominância de votos de mulheres naquela faixa. 


Para as variáveis que temos interesse: 

```{r fig.width=12,message=FALSE,echo=FALSE, warning=FALSE}
sortedDataAll = dataAll %>% arrange(gender) 

p = ggpairs(
  title = "Tabela de correlação das ambos os sexos", 
  mapping = aes(color=gender, alpha=0.1), 
  columns = c( "like", "shar", "sinc"),
  data=dataAll
) 

for(i in 1:p$nrow) {
  for(j in 1:p$ncol){
    p[i,j] <- p[i,j] + 
        scale_fill_manual(values=c("cyan","magenta")) +
        scale_color_manual(values=c("cyan","magenta"))  
  }
}
p
```

--- 

Percebemos então uma correlação moderada entre as variáveis de *Interesses Compartilhados* e *Sinceridade* com a variável dependente, Like. 

Se observarmos a correlação das outras variáveis com a variável like, temos:

```{r fig.width=12,message=FALSE,echo=FALSE, warning=FALSE}
  p = ggpairs(
    title = "Tabela de correlação para ambos os sexos", 
    mapping = aes(color=gender, alpha=0.1), 
    columns = c( "like", "amb", "attr", "fun", "intel",  "prob"),
    data=dataAll
  ) 
  for(i in 1:p$nrow) {
    for(j in 1:p$ncol){
      p[i,j] <- p[i,j] + 
        scale_fill_manual(values=c("cyan","magenta")) +
        scale_color_manual(values=c("cyan","magenta"))   
    }
  }
  p
```


### Os Modelos de Regressão 

1. Like sendo explicado pelo máximo de variáveis.
  Possivelmente o melhor modelo que iremos construir, pois engloba um maior número de variáveis que explicam a variável dependente. 
  
2. Like sendo explicado por todas menos 'fun' e 'attr'.
  Esse modelo será útil para utilizarmos como comparativo dos impactos causados ao ignorar duas variáveis que tem maior correlação com a variável dependente.
  
3. like sendo explicado por todas menos 'sinc' e 'shar'.
  Esse modelo ignora as variáveis que gostaríamos de investigar, nos permitindo comparar esse modelo com os outros.

#### Definindo os modelos de regressão

Para o modelo 1, que tem o máximo de variáveis possíveis temos: 
``` {r} 
modelo01_m = lm(like ~ attr + sinc + intel + fun + amb + shar +  prob, dataMen)  
modelo01_w = lm(like ~ attr + sinc + intel + fun + amb + shar +  prob, dataWomen)
summary(modelo01_m)
summary(modelo01_w)
```

Para o modelo 2, que não considera 'fun' e 'attr', temos: 
``` {r} 
modelo02_m = lm(like ~ sinc + intel + amb + shar +  prob, dataMen)  
modelo02_w = lm(like ~ sinc + intel + amb + shar +  prob, dataWomen)
summary(modelo02_m)
summary(modelo02_w)
```

Para o modelo 3, que não considera 'sinc' e 'shar' temos: 
``` {r} 
modelo03_m = lm(like ~ attr + intel + fun + amb +  prob, dataMen)  
modelo03_w = lm(like ~ attr + intel + fun + amb +  prob, dataWomen)
summary(modelo03_m)
summary(modelo03_w)
```


### Comentando métricas dos modelos 

---

### **Significância, Relevância e Magnitude dos Coeficientes**
##### **Significância**  
  Nosso modelo de regressão busca explicar uma variável _(like)_ que varia entre 0 e 10, com outras variáveis que variam entre 0 e 10. 

  Portanto, montando um modelo da forma:
$like = C_0 + C_1*ATTR + C_2*SHAR + ... + C_n * ATTR_n$

  O nosso modelo tentará estimar os coeficientes $C_0, C_1, C_2, ...,C_N$ de modo a otimizar a precisão do mesmo. 

  A estimativa para o valor dos coeficientes, tem um **intervalo de confiança** e um **valor-p** associados para cada um dos coeficientes, por convenção em um teste de hipotese caso esse valor-p seja **<= 5%** podemos rejeitar a hipotese nula, ou seja, caso o valor-p seja **<= 5%** podemos assumir que aquela variável e coeficiente estimados ajudam a explicar a variável dependente. 
  
  A significância relacionada aos coeficientes das variáveis independentes podem ser vistas na tabela pelos valores da coluna `Pr(>|t|)` ou através dos simbolos à direita da coluna. 

##### **Magnitude**
  Quanto a magnitude dos coeficientes, esperamos ver para o nosso modelo em específico, valores para os coeficientes entre 0 e 1. 
  
  Pois, mesmo que os valores para os coeficientes possam assumir quaisquer valores, no nosso caso como a variável Dependente e Independentes variam dentro do mesmo intervalo [0, 10]. Nossa intuição é que nosso modelo de regressão se assemelhe a uma média ponderada, onde o coeficiente seria o peso daquela característica. 
  
##### **Relevância** 
  Os coeficientes de regressão descrevem o relacionamento entre cada variável preditora e a resposta. O valor do coeficiente representa a mudança média na resposta, dado o aumento de uma unidade no preditor. Consequentemente, é fácil achar que variáveis com coeficientes maiores são mais importantes porque representam uma mudança maior na resposta.

  No entanto, as *unidades variam* entre os diferentes tipos de variáveis, o que inviabiliza sua comparação direta. Por exemplo, o significado da alteração de uma unidade é muito diferente se você estiver falando sobre temperatura, peso ou concentração de substâncias químicas.
  
  Também é importante salientar que o termo relevância não carrega nenhum valor moral ou ético sobre as variáveis, apenas indica o quanto elas contribuem para o valor da variável dependente.

  No nosso caso, as unidades e escalas de todas as variáveis são as mesmas. Por isso nossa intuição de que a somatória dos coeficientes das variáveis independentes se aproximaria de 1 parece se fazer presente. 
  
  Dada essa característica dos nossos dados, iremos dizer que as variáveis relevantes são aquelas que estão acima da média para montar nossa estimativa. Ou seja, um coeficiente $C$ é relevante se $C \ge 1 \div N$ onde $N$ é igual ao número de variáveis independentes, desta forma variáveis relevantes irão contribuir com maior força para a variável like.
    
##### **Modelo 1**
Todas as caracteristicas são significatívas, exceto AMB no caso das mulheres. 

* Características menos relevantes: 
  * Para homens: [**AMB, SINC, INTEL**]
  * Para mulheres: [**AMB, SINC, PROB**]
    
##### **Modelo 2 (sem fun e attr)**
Todas as caracteristicas são significatívas, exceto AMB para homens e mulheres. 

* Características menos relevantes: 
  * Para homens: [**AMB, INTEL**]
  * Para mulheres: [**AMB, PROB**]
  
##### **Modelo 3 (sem sinc e shar)**
Todas as caracteristicas são significatívas, exceto AMB para homens e mulheres. 
  
* Características menos relevantes: 
  * Para homens: [**AMB, INTEL**]
  * Para mulheres: [**AMB, PROB**]


### **R Squared e R Squared Adjusted**:

  R Squared indica uma medida de quão bem o modelo se ajusta aos dados. 
  É uma medida que varia de 0 a 1, onde 0 representa um modelo que não se adequa aos dados e valores próximos a 1 indicam modelos que se ajustam bem aos dados. 
  
  Um número maior de variáveis pode aumentar o R² de um modelo O Adjusted R² tenta compensar pelo número de variáveis.
  
##### **Modelo 1**
  Modelo mais abrangente.
  
* Homens:
  + $R² = 0.6431$
  + $adj. R² = 0.6419$
  
* Mulheres:
  + $R² = 0.7028$
  + $adj. R² = 0.7017$

##### **Modelo 2**
  Ao remover 'attr' e 'fun'.
  
* Homens:
  + $R² = 0.5041$
  + $adj. R² = 0.5028$
  
* Mulheres:
  + $R² = 0.5852$
  + $adj. R² = 0.5842$
  
##### **Modelo 3**
  Ao remover 'sinc' e  'shar'. 
  
* Homens:
  + $R² = 0.6165$
  + $adjusted R² = 0.6155$
  
* Mulheres:
  + $R² = 0.6652$
  + $adjusted R² = 0.6644$
  
  
### **Resíduos**
  Nas métricas de qualidade acima *Residual Standard Error* é a medida de ajuste do modelo de regressão. Teoricamente, todo modelo de regressão linear tem um erro associado ***E***. Devido a presença desse erro não somos capazes de predizer perfeitamente a variável *like* apartir das outras variáveis, sendo assim o *Residual Standard Error* (erro padrão residual) é o uma média da diferença entre as estimativas versus os dados reais observados. Ou seja, ao estimar, é provável que exista uma diferença entre a estimativa e o valor do like real com a magnitude do erro residual padrão.
  
##### **Modelo 1**
* O erro residual padrão é:
  + 1.049 para os homens.
  + 1.059 para as mulheres. 
  
Lembrando que segundo as métricas esse até agora é o nosso melhor modelo. 

##### **Modelo 2** 
* O erro residual padrão é:
  + 1.236 para os homens.
  + 1.25 para as mulheres. 

Com menos variáveis e um R² menor do que o modelo 1, o erro residual padrão aumenta como era de se esperar.
  
##### **Modelo 3**
* O erro residual padrão é:
  + 1.087 para os homens.
  + 1.123. para as mulheres. 
  
Além do R² desse modelo ser melhor do que o R² do modelo 2, o erro residual padrão também é menor. 

## **Conclusões**
  Neste relatório utilizamos de modelos lineares para tentar explicar características que possam  influenciar um indivíduo gostar de outro em um encontro relâmpago, ou speed dating. 
  
  Partimos de modelos mais simples, para modelos mais complexos analisando o quão bem o modelo em questão explica a variável independente. 

  Neste processo identificamos que algumas variáveis acabam sendo associadas a coeficientes proporcionais a sua importância em estimar a nossa variável dependente. 

  Também veríficamos ao comparar os modelos que um modelo que leva em consideração ATTR e FUN estima LIKE com melhores métricas, do que um modelo que utilize SINC e SHAR. 
  Porém ao utilizar essas variáveis em conjunto, conseguimos um modelo com métricas ainda melhores.
  
  Por fim, percebemos também que a variável que representa o interesse em comum tem mais influência que a sinceridade.

  Um modelo de regressão ideal, explicaria toda a variância e teria portanto uma métrica R² próxima a 1. Porém, vale salientar que existem fatores aleatórios que não foram considerados pelo modelo que afetam a qualidade do mesmo, por exemplo, as cidades de origem dos indivíduos e por consequência a distância entre os indivíduos, preferências políticas, se são da mesma etnia, etc. 